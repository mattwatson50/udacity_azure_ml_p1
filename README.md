# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

This data contains information about people and their banking history and whether a marking campaign was successful for them. It can be used as a way to interpret whether or not a bank should spend resources marketing towards each individual.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

The pipeline architecture contains a few major steps. First we ingest the data into an Azure Dataset. Then we run a HyperDrive experiment on it with random sampling logistic regression. Once that is complete we look for the best performing model. To benchmark we then run an AutoML experiment on the same data, saving that model out via the Azure ONNX converter. We are then comparing the different models that were generated to understand the differences and choose the best one.

**What are the benefits of the parameter sampler you chose?**

I chose some standard parameters for random sampling with SciKit Learn logistic regression. C, solver, penalty, and max iter C is the regularization parameter that controls the inverse of the regularization strength. Solver helps to optimize the fit for the logistic regression model. Penalty provides the type of regularization to be used. Max iter is the number of iterations to use.

**What are the benefits of the early stopping policy you chose?**

Early stopping allows for experiments that are failing heavily to end early. It's a good way to save on resource when an experiment is heading for a dead end.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
