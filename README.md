# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

This data contains information about people and their banking history and whether a marking campaign was successful for them. It can be used as a way to interpret whether or not a bank should spend resources marketing towards each individual.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

The best performing model was the automl model a VotingEnsemble model.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

The pipeline architecture contains a few major steps. First we ingest the data into an Azure Dataset. Then we run a HyperDrive experiment on it with random sampling logistic regression. Once that is complete we look for the best performing model. To benchmark we then run an AutoML experiment on the same data, saving that model out via the Azure ONNX converter. We are then comparing the different models that were generated to understand the differences and choose the best one.

**What are the benefits of the parameter sampler you chose?**

I chose some standard parameters for random sampling with SciKit Learn logistic regression, based on what was already being used in train.py, C and max iter. C is the regularization parameter that controls the inverse of the regularization strength. Max iter is the number of iterations to use.

**What are the benefits of the early stopping policy you chose?**

Early stopping allows for experiments that are failing heavily to end early. It's a good way to save on resource when an experiment is heading for a dead end.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

AutoML chose a voting ensemble model which contains the predicitons multiple models in order to achieve the best result.

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

There was not a huge difference between the two models. The hyperdrive model had an accuracy of 0.9096 and the AutoML model had an accuracy of 0.9165. However the work that was required for the hyperdrive model was much larger than what was needed for the AutoML model. We simply needed to clean the data and get it ready for the AutoML model and it did the rest. Potentially we could get a higher accuracy for the hyperdrive model with more trial and error. So working with hyperdrive allows for more opportunity to fine tune the model.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

Running more hyperdrive experiments with different hyperparameters could yield better results. I would suggest performing more hyperdrive experiments instead of just accepting AutoML as the best answer. We could also supply AutoML with more chances to run as well to see if it could yield better results.

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
